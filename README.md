# ğŸ“Š Data Quality Pipeline - Retail Store Sales

## ğŸ¯ Objectif

Pipeline complet de Data Quality pour auditer, nettoyer et monitorer la qualitÃ© des donnÃ©es de ventes (**Retail Store Sales**) basÃ© sur les **6 piliers de la qualitÃ© des donnÃ©es**.
Le projet traite un dataset brut contenant des anomalies intentionnelles (valeurs manquantes, doublons, incohÃ©rences) pour simuler un environnement rÃ©el.

---

## ğŸ“ Structure du Projet

```
data-quality-pipeline/
â”œâ”€â”€ docker-compose.yml          # Services (MariaDB, Superset, OpenMetadata)
â”œâ”€â”€ README.md                   # Ce fichier
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # DonnÃ©es brutes (Retail_Store_Sales.csv)
â”‚   â””â”€â”€ cleaned/                # DonnÃ©es nettoyÃ©es (Retail_Cleaned.csv)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_dataset.py     # GÃ©nÃ©ration du dataset dirty
â”‚   â”œâ”€â”€ import_data.py          # Import dans MariaDB (retail_raw)
â”‚   â”œâ”€â”€ cleaning_pipeline.py    # Nettoyage et transformation
â”‚   â”œâ”€â”€ great_expectations_validator.py  # Tests de validation
â”‚   â”œâ”€â”€ sweetviz_profiling.py   # Comparaison Avant/AprÃ¨s
â”‚   â””â”€â”€ superset_init.sh        # Init Dashboard Superset
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ sweetviz_compare_report.html # Rapport de profilage interactiv
â”‚   â””â”€â”€ cleaning_report.json    # Stats de nettoyage
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_tables.sql       # SchÃ©ma (retail_raw, retail_cleaned)
â”‚   â””â”€â”€ quality_kpis.sql        # Calcul des mÃ©triques SQL
â””â”€â”€ governance/
    â””â”€â”€ asset_catalog.json      # MÃ©tadonnÃ©es
```

---

## ğŸš€ Installation et DÃ©marrage

### PrÃ©requis

- Python 3.10+
- Docker & Docker Compose

### 1. DÃ©marrer les services

```bash
docker-compose up -d
```

*Services : MariaDB (3307), Superset (8088), OpenMetadata (8585)*

### 2. ExÃ©cuter le Pipeline

```bash
# GÃ©nÃ©rer et importer les donnÃ©es
python scripts/generate_dataset.py
python scripts/import_data.py

# Nettoyer et valider
python scripts/cleaning_pipeline.py
python scripts/great_expectations_validator.py

# GÃ©nÃ©rer le rapport de profilage
python scripts/sweetviz_profiling.py
```

### 3. Visualisation (Superset)

AccÃ©der Ã  [http://localhost:8088](http://localhost:8088) (admin/admin).
Initialiser la connexion :

```bash
docker exec dq_superset bash /app/superset_init.sh
```

---

## ğŸ“Š Les 6 Piliers de QualitÃ©

| Pilier | ProblÃ¨me IdentifiÃ© | Solution AppliquÃ©e | Score |
|--------|-------------------|--------------------|-------|
| **ComplÃ©tude** | Manque Produit/Prix | Imputation (Unknown/MÃ©diane) | 100% |
| **Exactitude** | Format Dates/Villes | Standardisation | 100% |
| **ValiditÃ©** | Prix nÃ©gatifs | Conversion Valeur Absolue | 100% |
| **CohÃ©rence** | Total â‰  Prix * QtÃ© | Recalcul strict | 100% |
| **UnicitÃ©** | Doublons Transactions | DÃ©duplication | 100% |
| **ActualitÃ©** | Dates futures | Validation date | 100% |

---

## ğŸ“ˆ Dataset : Retail Store Sales (Dirty)

- **Source** : GÃ©nÃ©ration synthÃ©tique (Python)
- **Volume** : ~15 300 lignes
- **Colonnes** : 11
- **QualitÃ© Initiale** : ~8% d'erreurs injectÃ©es

### Colonnes ClÃ©s

- `Transaction_ID` : Unique aprÃ¨s nettoyage
- `Product_Name` : Produit vendu
- `Total_Amount` : Montant de la transaction
- `City` : Ville du magasin

---

## ğŸ‘¤ Auteur

**ICOM - Master 2 BI & Analytics**  
AnnÃ©e universitaire 2025-2026  
**Ã‰tudiants :**  
Idir TABET  
Nassim TABET  
Mohammed ABBAOUI
